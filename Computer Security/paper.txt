As the amount of code increases, the task of securing code quickly becomes unwieldy.  So it was inevitable that researchers began looking into the possibility of using automation to assist in securing software.  The various approaches can be grouped into roughly 4 categories: static analysis; dynamic analysis; vulnerability mitigation; creating a programming language or subset of an existing programming language from scratch.  Each approach has its advantages and drawbacks, and none is absolutely superior to the others.  It all depends on the context.

Static Analysis:

These tools operate by scanning source code for various known vulnerabilities.  One drawback is that they can only scan for known threats.  Another is that these tools can only detect errors; the user must know how to fix these errors.  While automatically removing all security bugs from a program is considered infeasible in practice, being able to remove all or most known bugs decreases the likelihood of a program being exploited.  The following is an overview of the most prominent static analysis tools.

ITS4: Developed by researchers at Reliable Software Technologies (now Cigital), ITS4 (short for It's the Software Stupid! Security Scanner) is a tool for analyzing C/C++ source code.  ITS4 performs lexical analysis on source code, building a stream of tokens and attempts to match them against known vulnerable functions in a database.  The decision was made to use lexical analysis rather than parsing because ITS4 is build to give programmers feedback while code is being written, and parsing cannot be done on the fly.

RATS: The Rough Auditing Tool for Security is a tool developed by Secure Software Solutions, which is able to analyze C/C++, Perl, PHP, and Python source code.  This tool performs lexical analysis similar to ITS4, looking for potentially dangerous function calls by matching source code against a database of vulnerabilities.  It produces a list of potential problems, annotated with risk gradings and short descriptions.  RATS is available under the GPL.

FlawFinder: Developed by David Wheeler, this tool shares many similarities with RATS and ITS4.  In fact, when the RATS and FlawFinder teams realized they were developing similar tools using similar approaches at roughly the same time, they decided on a common release date, agreed to mention each other in their announcements, and planned to combine the two tools into one in the future.  Like ITS4 and RATS, FlawFinder performs lexical analysis on C/C++ source code.  Given source code, the tool produces a list of potential vulnerabilities sorted by risk level, which is determined not just by the function name but also the values of the parameters.  FlawFinder is also available under the GPL.

Splint: Secure Programming Lint, or Splint for short, was developed by David Evans and David Larochelle.  It was originally known as LCLint, taking its name and some functionality from Lint, a popular C static analysis tool.  Splint takes a different approach from ITS4, RATS, and FlawFinder.  Rather than lexical analysis, Splint uses programmer-provided semantic comments, or annotations, to perform syntactic analysis based on the program parse tree.  The annotations specify constraints on program functions, such as properties the function requires and ensures.  For instance, a programmer may annotate an invocation of strcpy to require that the destination buffer is big enough to hold the data from the source buffer.  This type of analysis can be much more accurate than lexical analysis in differentiating between correct and incorrect use of functions.

MOPS: The MOdel Checking Programs for Security properties tool (MOPS) was developed by David Wagner et. al.  It checks a program for temporal security properties, properties relating to the order of sensitive operations.  One example of a MOPS security property is checking whether a setuid-root program drops the root privilege before executing an untrusted program.  MOPS models properties as finite state automata, and programs as push-down automata, and checks if any path in the control flow graph reaches states corresponding to violations.  If so, MOPS reports the path that leads to violations in error traces.  While powerful, MOPS currently has several severe limitations: it can only check single-threaded programs; no support for variable aliasing; does not consider control flow changes such as libraries loaded at runtime.

Dynamic Analysis:

Because there are security problems that are undecidable from static analysis, dynamic analysis is often used to augment static analysis.  Dynamic analysis essentially places programs under test loads and checks for interesting results.  The following tools insert instrumentation into programs and report what happens when these programs are subjected to generated test cases.

Sharefuzz: Fuzz is the notion of trying to crash programs by presenting it with test inputs.  ShareFuzz generates inputs such as unusually long strings or strings containing "%n" to test for things like buffer overflows and format string vulnerabilities.  If a program core dumps, it is likely to contain one of these vulnerabilities.

ElectricFence: This tool is a malloc() debugger, stopping a program on the exact instruction that overruns or underruns a malloc() buffer.

MemWatch: Misuse of memory such as multiple frees of the same memory region or using a region after it has been freed can result in similar consequences as buffer overflows.  MemWatch is a memory leak detection tool.  It can help detect misuses such as double-frees, unfreed memory, wild pointer writes, and more.

Vulnerability Mitigation:

The idea behind vulnerability mitigation is to change the system environment or functionality such that vulnerabilities are rendered harmless, or atleast less harmful.  One big advantage of vulnerability mitigation over static analysis or dynamic analysis techniques is that these techniques can provably secure the targets they were designed to protect, and will produce no false positives.  Unfortunately, like static analysis, they can only protect against known threats.  Furthermore, the bugs are still present in the original programs.  So if new methods are found to exploit these bugs, then vulnerability mitigation techniques may be rendered completely ineffectual.

StackGuard: Perhaps the best known vulnerability mitigation tool, StackGuard was developed by Crispin Cowan et. al. in response to stack-smashing buffer overflow attacks.  The basic idea is that such an attack overwrite everything on the way to the target, the return address.  StackGuard places a canary value on the stack next to the return address.  When the function returns, if the canary value has been changed, the program is aborted rather than jumping to the (presumably) corrupted return address.

ProPolice: An independent implementation that also uses StackGuard's canary idea, it adds some new ideas.  One of the most novel ideas introduced is rearranging the stack variables so that char buffers are always allocated on the stack such that if they are over-run, other local variables and pointers will not be touched, and only other char buffers and the old base pointer can be modified.  The canary is placed between the buffers and the old base pointer so that any such overflow that modifies the old base pointer will be immediately detected.  However, unlike StackGuard, ProPolice injects its modifications early in the compilation process, meaning that its safeguards may be disrupted by the compiler.

FormatGuard: FormatGuard was the first vulnerability mitigation tool for format string attacks.  It detects and halts exploitation of the printf command by using C preprocessor macros to count function arguments at compile time and uses a runtime wrapper around printf to match the expected number of arguments against the actual number of arguments.  FormatGuard patches glibc with minimal compatibility and performance costs.

Secure Language:

One can argue that most, if not all, software security problems arise because of unsafe languages.  So why not restrict programmers to a safe subset of an existing language, or create a safe language from scratch?  This is the principle behind the following languages.

CCured: CCured is a source-to-source translator for C that addresses the problem of memory safety violations.  It inserts the minimal number of run-time checks required to prevent all memory safety violations.  The resulting program is memory-safe, halting before performing any memory violating action such as overrunning a buffer.  Unfortunately, this approach is not without drawbacks.  CCured's program transformations incurs a performance cost anywhere between 10% to 60%, and there are parts of programs that CCured does not understand, requiring manual modification.

Cyclone: Cyclone is a dialect of C language that aims to rules out program errors such as buffer overflows, dangling pointers, format string attacks, and others.  Cyclone, like CCured, performs static analysis on C code and inserts run-time checks.  It also inserts annotations intended to aid static analysis or maintain extra information for the run-time checks.  Like CCured, Cyclone incurs performance costs.  While I/O-bound applications achieved near-zero overhead when ported from C to Cyclone, CPU-bound applications saw slowdowns by up to a factor of 3 when ported.  The main difference between CCured and Cyclone is that CCured seeks to abstract memory management away from the programmers, while Cyclone tries to preserve programmers' control over data representation and memory management as much as possible.

Spark: Spark is an annotated subset of Ada, designed to be a secure, formally-defined, unambiguous language.  Developed at the University of Southampton, Spark is now maintained by Praxis High Integrity Systems Ltd.  It sought to eliminate potential ambiguities and insecurities by omitting problematic Ada features such as unrestricted tasking and introducing annotations.  The Spark Examiner, part of the Spark Toolset available from Praxis, performs two kinds of static analysis on Spark programs.  It first checks for language conformance, verifying that the program is free of data flow errors and conforms with the design information specified by annotations.  The second type of checks proves that the program has certain properties.  The simplest example is proving that a given Spark program is exception free.  These proofs can also be demonstrate that the program maintains certain safety or security properties.